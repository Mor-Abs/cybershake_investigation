{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code Description:\n",
    "Calculates the IM residuals from Cybershake simulations and Empirical calculations\n",
    "\n",
    "Author: Morteza\n",
    "Version History:\n",
    "- Version 1.0: December 20, 2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from utils import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path and directory works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getcwd()\n",
    "\n",
    "data_version = \"combined_v20p6_v24p8\"\n",
    "sim_dir = f\"/mnt/hypo_data/mab419/Cybershake_Data/{data_version}\" #dpath to simulation data\n",
    "emp_dir = f\"/mnt/hypo_data/mab419/Empirical_Data/{data_version}\"  # dpath to emirical calculation data\n",
    "res_dir = f\"/mnt/hypo_data/mab419/Residual_Data/{data_version}\"  # dpath to residual pickle data\n",
    "plot_dir = \"/mnt/hypo_data/mab419/mab419_cybershake_investigation/usages/plots/\"\n",
    "\n",
    "base_dir = \"/mnt/hypo_data/mab419/mab419_cybershake_investigation/base_data\"  # dpath to dirctory of base data\n",
    "\n",
    "# File names of the stations data\n",
    "stations_ll = \"non_uniform_whole_nz_with_real_stations-hh400_v20p3_land.ll\"\n",
    "stations_vs30 = \"non_uniform_whole_nz_with_real_stations-hh400_v20p3_land.vs30\"\n",
    "stations_z = \"non_uniform_whole_nz_with_real_stations-hh400_v20p3_land.z\"\n",
    "\n",
    "# File  name of 'Fault-Site-Source' database\n",
    "site_source_db = \"new_flt_site_source.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [10:21<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "sim_data_dic = util.load_sim_data(\n",
    "    sim_dir=sim_dir,\n",
    "    # faults=[\"Tauranga05\"],\n",
    "    component=\"geom\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_statistic_dic = util.calc_sim_statistics(\n",
    "    sim_dir=sim_dir,\n",
    "    # faults=[\"FiordSZ03\"],\n",
    "    component=\"geom\",\n",
    "    proc_flag=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample\n",
    "tt = sim_statistic_dic[\"FiordSZ03\"]\n",
    "temp_df = tt.sel(statistics=\"mean\").to_pandas()\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Empirical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_statistic_dic = util.load_emp_data(\n",
    "    emp_dir=emp_dir,\n",
    "    # faults=[\"FiordSZ03\"],\n",
    "    component=\"geom\",\n",
    "    proc_flag= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT Normalized Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_dic_not_normal = util.calc_mean_residual(\n",
    "    sim_dic=sim_statistic_dic,\n",
    "    emp_dic=emp_statistic_dic,\n",
    "    faults=[],\n",
    "    IMs=[],\n",
    "    normalized=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "residual_dic_not_normal[\"FiordSZ03\"].loc[:, \"PGV\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_dic_normal = util.calc_mean_residual(\n",
    "    sim_dic=sim_statistic_dic,\n",
    "    emp_dic=emp_statistic_dic,\n",
    "    faults=[],\n",
    "    IMs=[],\n",
    "    normalized=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "residual_dic_normal[\"FiordSZ03\"].loc[:, \"PGV\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtian Rrup-Residual Relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading station-r-residual dict from previous pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Import file name\n",
    "file_name = \"Station_Rrup_Res_Dic.pkl\"\n",
    "file_path = os.path.join(res_dir, file_name)\n",
    "with open(file_path, \"rb\") as file:\n",
    "    Station_Rrup_Res_Dic = pickle.load(file)\n",
    "\n",
    "print(\"Dictionary loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating new dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claculating Station_Rrup_Residula Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derermine which residuals to proceed\n",
    "Resduals_Results_Dic = residual_dic_not_normal\n",
    "# Resduals_Results_Dic = residual_dic_normal\n",
    "\n",
    "Faults = list(Resduals_Results_Dic.keys())  \n",
    "db_file_path = os.path.join(base_dir, site_source_db)\n",
    "\n",
    "IMs = [\"PGV\"]  # Replace with your intensity measures\n",
    "IMs = [\n",
    "    \"pSA_0.01\",\n",
    "    \"pSA_0.02\",\n",
    "    \"pSA_0.03\",\n",
    "    \"pSA_0.04\",\n",
    "    \"pSA_0.05\",\n",
    "    \"pSA_0.075\",\n",
    "    \"pSA_0.1\",\n",
    "    \"pSA_0.12\",\n",
    "    \"pSA_0.15\",\n",
    "    \"pSA_0.17\",\n",
    "    \"pSA_0.2\",\n",
    "    \"pSA_0.25\",\n",
    "    \"pSA_0.3\",\n",
    "    \"pSA_0.4\",\n",
    "    \"pSA_0.5\",\n",
    "    \"pSA_0.6\",\n",
    "    \"pSA_0.7\",\n",
    "    \"pSA_0.75\",\n",
    "    \"pSA_0.8\",\n",
    "    \"pSA_0.9\",\n",
    "    \"pSA_1.0\",\n",
    "    \"pSA_1.25\",\n",
    "    \"pSA_1.5\",\n",
    "    \"pSA_2.0\",\n",
    "    \"pSA_2.5\",\n",
    "    \"pSA_3.0\",\n",
    "    \"pSA_4.0\",\n",
    "    \"pSA_5.0\",\n",
    "    \"pSA_6.0\",\n",
    "    \"pSA_7.5\",\n",
    "    \"pSA_10.0\",\n",
    "]\n",
    "\n",
    "Station_Rrup_Res_Dic = {}\n",
    "\n",
    "# Precompute fault mapping\n",
    "fault_mapping = util.fault_mapping_from_flt_site_source_db(db_file_path)\n",
    "\n",
    "# Open the HDF5 file once\n",
    "with h5py.File(db_file_path, \"r\") as file_handle:\n",
    "    for im in IMs:\n",
    "        print(f\"IM= {im}\")\n",
    "        if im not in Station_Rrup_Res_Dic:\n",
    "            Station_Rrup_Res_Dic[im] = {}\n",
    "\n",
    "        # Process each fault in parallel\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            results = executor.map(\n",
    "                lambda fault: (\n",
    "                    fault,\n",
    "                    Resduals_Results_Dic[fault][im],  # Residual data\n",
    "                    util.parallel_multi_station_get_distance_from_db(\n",
    "                        stations=list(\n",
    "                            Resduals_Results_Dic[fault][im].index\n",
    "                        ),  # Extract stations\n",
    "                        fault_name=fault,\n",
    "                        file_handle=file_handle,\n",
    "                        fault_mapping=fault_mapping,\n",
    "                    ),\n",
    "                ),\n",
    "                Faults,\n",
    "            )\n",
    "\n",
    "            # Store results in the dictionary\n",
    "            for fault, res_df, station_rrups_df in results:\n",
    "                # Merge residuals and distances\n",
    "                station_rrup_res_df = pd.merge(\n",
    "                    station_rrups_df, res_df.reset_index(), on=\"station\", how=\"left\"\n",
    "                )\n",
    "                station_rrup_res_df = station_rrup_res_df.dropna(subset=[\"rrup\"])\n",
    "                Station_Rrup_Res_Dic[im][fault] = station_rrup_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "Station_Rrup_Res_Dic['pSA_0.01']['HikHBaymax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the calculated station-r-residual dict to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory exists\n",
    "if Path(res_dir).exists():\n",
    "    prompt = input(\n",
    "        f\"The following path already exists! Do you want to delete and renew (1) or terminate (2)? \\n{res_dir}\\n\"\n",
    "    )\n",
    "    if prompt == \"1\":\n",
    "        # Remove the folder\n",
    "        shutil.rmtree(res_dir)\n",
    "        print(f\"Deleted and renewed the path: \\n{res_dir}\")\n",
    "        os.makedirs(res_dir, exist_ok=False)\n",
    "    elif prompt == \"2\":\n",
    "        print(\"Terminating the process.\")\n",
    "        exit()\n",
    "    else:\n",
    "        print(\"Invalid input. Terminating the process.\")\n",
    "        exit()\n",
    "else:\n",
    "    os.makedirs(res_dir, exist_ok=False)\n",
    "    print(f\"Created the path: \\n{res_dir}\")\n",
    "\n",
    "# File path to save the dictionary\n",
    "file_name = \"Station_Rrup_Res_Dic.pkl\"\n",
    "file_path = os.path.join(res_dir, file_name)\n",
    "\n",
    "# Save the dictionary\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(Station_Rrup_Res_Dic, file)\n",
    "\n",
    "print(f\"Dictionary saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morteza",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
